{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./Dataset/Training/Data\"\n",
    "\n",
    "file_list = os.listdir(\"./Dataset/Training/Data\")\n",
    "nii_files = [os.path.join(train_dir, file) for file in file_list if file.endswith(\".nii\")]\n",
    "glm_files = [file for file in nii_files if file.endswith(\"glm.nii\")]\n",
    "for glm in glm_files:\n",
    "    nii_files.remove(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 284, 347)\n",
      "(29, 29)\n",
      "(29, 29)\n",
      "(29, 29)\n"
     ]
    }
   ],
   "source": [
    "nib.Nifti1Header.quaternion_threshold = -1e-06  # https://github.com/nipy/nibabel/issues/626\n",
    "img = np.array(nib.load(nii_files[0]).dataobj).astype(np.float64)\n",
    "\n",
    "### padding\n",
    "img = np.pad(img, ((14,14),(14,14),(14,14)),'constant', constant_values=(0))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "i,j,k =100,100,100\n",
    "# center (14,14)\n",
    "print(img[i-14:i+15, j-14:j+15, k].shape)\n",
    "print(img[i, j-14:j+15, k-14:k+15].shape)\n",
    "print(img[i-14:i+15, j, k-14:k+15].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./Dataset/Training/Data\"\n",
    "# data_file = \"1000_3.nii\"\n",
    "data_file = None\n",
    "\n",
    "if data_file is None and data_dir:\n",
    "    file_list = os.listdir(data_dir)\n",
    "    nii_files = [os.path.join(data_dir, file) for file in file_list if file.endswith(\".nii\")]\n",
    "    glm_files = [file for file in nii_files if file.endswith(\"glm.nii\")]\n",
    "    for glm in glm_files:\n",
    "        nii_files.remove(glm)\n",
    "\n",
    "elif isinstance(data_file, str):\n",
    "    nii_files = [os.path.join(data_dir, data_file)]\n",
    "    glm_files = [nii_files[0].split(\".n\")[0] + \"_glm.nii\"]\n",
    "\n",
    "\n",
    "### settings for nibabel ###\n",
    "nib.Nifti1Header.quaternion_threshold = -1e-06\n",
    "data_list = [np.array(nib.load(data).dataobj).astype(np.float64) for data in nii_files]\n",
    "\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_file=None, transform=None):\n",
    "        \n",
    "        if data_file is None and data_dir:\n",
    "            file_list = os.listdir(data_dir)\n",
    "            nii_files = [os.path.join(data_dir, file) for file in file_list if file.endswith(\".nii\")]\n",
    "            glm_files = [file for file in nii_files if file.endswith(\"glm.nii\")]\n",
    "            for glm in glm_files:\n",
    "                nii_files.remove(glm)\n",
    "\n",
    "        elif isinstance(data_file, str):\n",
    "            nii_files = [os.path.join(data_dir, data_file)]\n",
    "            glm_files = [nii_file.split(\".n\")[0] + \"_glm.nii\"]\n",
    "            \n",
    "        \n",
    "        ### settings for nibabel ###\n",
    "        nib.Nifti1Header.quaternion_threshold = -1e-06\n",
    "        \n",
    "        self.data_list = [np.array(nib.load(data).dataobj).astype(np.float64) for data in nii_files]\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
